{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMR2HO3lKfPdV8XQ8VEDfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hakimozcan/Generative-AI/blob/main/working_with_the_openai_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "R1fYqsDy_OjI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQZg2WBbpjeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4543cd7a-4daf-4cd3-9ece-9c28b4d2c70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI Python API library\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "QpzbGDul_SVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OpenAI Python API library\n",
        "import openai"
      ],
      "metadata": {
        "id": "rt7JZNPJqC7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Introduction to the OpenAI API\n",
        "\n"
      ],
      "metadata": {
        "id": "WolVslbI_Zh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OpenAI API provides a platform to access and utilize advanced artificial intelligence models developed by OpenAI, including the widely-known ChatGPT. It serves as a tool to integrate AI functionalities into various applications, without requiring in-depth knowledge of AI or machine learning. The API acts as a bridge between the user's requests and the AI models, allowing for customization and application in a range of real-world tasks using Python programming. This makes it a valuable resource for software and data profesionals looking to incorporate AI features into their products and services."
      ],
      "metadata": {
        "id": "10vWjvBg-EK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API request"
      ],
      "metadata": {
        "id": "3BjgYNsr-nz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making requests to the OpenAI API involves understanding and using multiple API endpoints. Authentication is required for accessing these endpoints through a unique API key. Using the OpenAI API may incur costs, depending on the model and the size of data processed. Thus, it's important to refer to API documentation for detailed instructions on endpoint usage and authentication setup. To make a request, one can use OpenAI's Python library. This involves setting up an API client in Python, authenticating with the API key, and then creating and sending a request to a specific endpoint, such as the completions endpoint for text generation."
      ],
      "metadata": {
        "id": "zXATFKRIATF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "openai.api_key = \"<OPENAI_TOKEN>\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  # Specify the correct model\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"Who developed ChatGPT?\"\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "aTaB4Arv_aJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f30ae6a-7050-4c5e-a9a8-5b3c6b2e5a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-8XRRgjALKwS3c1j4Z90aWJl7ii6ob\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1702981016,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nChatGPT was developed by OpenAI, a research institute and AI development\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 6,\n",
            "    \"completion_tokens\": 16,\n",
            "    \"total_tokens\": 22\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the text from the response\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNZjlwx60E1T",
        "outputId": "7ee53954-bdca-4f3c-f424-9460be3be244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ChatGPT was developed by OpenAI, a research institute and AI development\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's API offers a range of models, beyond its well-known GPT series, including text-based ones and the Whisper model for audio transcription and translation. Key API endpoints include:\n",
        "\n",
        "**Completions**: For single-turn tasks, generating logical responses to prompts.\n",
        "\n",
        "**Chat**: Supports multi-turn tasks, useful for conversations, tutoring, and coding.\n",
        "\n",
        "**Moderation**: Checks content against OpenAI's policies, detecting potential violations."
      ],
      "metadata": {
        "id": "AHmBqIiZDaI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: OpenAI's Text and Chat Capabilities"
      ],
      "metadata": {
        "id": "RU_DVK3b_obu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find and replace"
      ],
      "metadata": {
        "id": "-IuT7efSA5aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
        "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "# Extract and print the response text\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RFUlU0R_os1",
        "outputId": "e815dafa-0542-4601-9a5d-a6c2ead4367c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "A plane is a vehicle that is typically powered by jet engines or propellers. It has wings and is designed to carry passengers and/or cargo through the air. Planes have become an essential mode of transportation in today's world, allowing people to travel long distances quickly and easily. They are also used for various purposes such as military operations, commercial aviation, and leisure travel. Planes are often associated with adventure, exploration, and global connectivity. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text summarization"
      ],
      "metadata": {
        "id": "DshpXe-JBoik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
        "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=400,\n",
        "  temperature=0.5\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "F8VBnS4E_ovc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c86a0f-434e-422a-8ec8-a6927133016a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "- Investment involves committing money to an enterprise for potential profit.\n",
            "- Careful analysis, risk assessment, and diversification are important for successful investments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content generation"
      ],
      "metadata": {
        "id": "nxbkiUf8F_Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a catchy slogan for a new fast-food Chinese restaurant\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "ktEww1kkF_NY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca5b554-f0c4-4745-a2b9-c28fcb3cfdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Satisfy your cravings with a taste of the East at lightning speed!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying text sentiment"
      ],
      "metadata": {
        "id": "6-SxVSZaJz4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"\"\"classify the sentiment of the following statements as either negative, positive, or neutral:\n",
        "Unbelievably good!\n",
        "Shoes fell apart on the second use.\n",
        "The shoes look nice, but they aren't very comfortable.\n",
        "Can't wait to show them off!\n",
        "\"\"\",\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "P-wndhdaF_Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5cc24f-e70c-4c33-9056-6c5c96ae5e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive\n",
            "Negative\n",
            "Negative\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorizing"
      ],
      "metadata": {
        "id": "SptlDUSCKDLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"Categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, and LVMH\",\n",
        "  max_tokens=100,\n",
        "  temperature=0.5\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "-kJj6mYqF_SH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0097a55-2b50-4c3f-dc76-c99f35e9483d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Technology: Apple, Microsoft, Alphabet, Amazon, NVIDIA, Meta, Tesla\n",
            "2. Energy: Saudi Aramco\n",
            "3. Finance: Berkshire Hathaway\n",
            "4. Luxury Goods: LVMH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Chat Completion endpoint"
      ],
      "metadata": {
        "id": "w1jSzrj7vg_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the ChatCompletion endpoint\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\",\n",
        "     \"content\": \"You are a helpful data science tutor.\"},\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "# Extract and print the assistant's text response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1QLfu3R2vhKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe6934c-09a1-45e7-b45e-3cab30fe0447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8XRSHkXiMj2AZICrqntOga5DB2ZQm\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1702981053,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"A for loop and a while loop are both control flow structures that allow you to repeat a certain block of code multiple times, but there are some differences between them.\\n\\nA for loop is typically used when you know the number of iterations in advance. It consists of three parts: initialization, condition, and increment/decrement. The initialization is where you set the initial value of the loop variable, the condition is checked before each iteration to determine whether the loop should continue or not, and the increment/decrement is the operation performed to change the loop variable after each iteration. For example, a typical for loop in Python could be written as:\\n\\n```python\\nfor i in range(5):\\n    print(i)\\n```\\n\\nIn this example, the loop variable `i` is initialized to 0, the condition `i < 5` is checked before each iteration, and `i` is incremented by 1 after each iteration.\\n\\nOn the other hand, a while loop is used when you don't know the number of iterations in advance or the loop should continue as long as a certain condition is true. It consists of a condition that is checked before each iteration, and if the condition is true, the loop body is executed. After each iteration, the condition is checked again, and the loop continues until the condition becomes false. For example, a typical while loop in Python could be written as:\\n\\n```python\\ni = 0\\nwhile i < 5:\\n    print(i)\\n    i += 1\\n```\\n\\nIn this example, the loop starts with the variable `i` set to 0, and the condition `i < 5` is checked before each iteration. The loop body is executed as long as the condition is true, and `i` is incremented by 1 after each iteration.\\n\\nIn summary, the main difference is that a for loop is generally used when you have a known number of iterations, while a while loop is used when the number of iterations is not known in advance or when you need more flexibility in controlling the loop flow.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 32,\n",
            "    \"completion_tokens\": 416,\n",
            "    \"total_tokens\": 448\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code explanation"
      ],
      "metadata": {
        "id": "3ao3zcQa303S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
        "import numpy as np\n",
        "\n",
        "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
        "heights = heights_dict.values()\n",
        "print(np.mean(heights))\n",
        "\"\"\"\n",
        "\n",
        "# Create a request to the ChatCompletion endpoint\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": instruction}],\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "fJYhO2-h32F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-turn chat completions with GPT"
      ],
      "metadata": {
        "id": "ICD6byvx29EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that messages are sent to the Chat Completions endpoint as a list of dictionaries, where each dictionary provides content to a specific role from either system, user, or assistant. For single turn tasks, no content is sent to the assistant role - the model relies only on its existing knowledge, the behaviors sent to the system role, and the instruction from the user."
      ],
      "metadata": {
        "id": "zSbPjDiy3CTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "   model=\"gpt-3.5-turbo\",\n",
        "   # Add a user and assistant message for in-context learning\n",
        "   messages=[\n",
        "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the min() function does.\"},\n",
        "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
        "   ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "JeRLOIeR2-Qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc446e41-fbf4-4ea1-db67-45ad1d02b7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type() function is used to determine the type of an object or variable in Python. It takes an object or variable as its parameter and returns its corresponding data type. The data types could be int, float, str, list, tuple, dictionary, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-context learning"
      ],
      "metadata": {
        "id": "1Pvx1mnZ4F9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "   model=\"gpt-3.5-turbo\",\n",
        "   # Add a user and assistant message for in-context learning\n",
        "   messages=[\n",
        "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the min() function does.\"},\n",
        "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
        "   ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "_XF-ioRr4GFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an AI chatbot"
      ],
      "metadata": {
        "id": "IpEeTbROBzEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
        "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
        "\n",
        "for q in user_msgs:\n",
        "    print(\"User: \", q)\n",
        "\n",
        "    # Create a dictionary for the user message from q and append to messages\n",
        "    user_dict = {\"role\": \"user\", \"content\": q}\n",
        "    messages.append(user_dict)\n",
        "\n",
        "    # Create the API request\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=10\n",
        "    )\n",
        "\n",
        "    # Convert the assistant's message to a dict and append to messages\n",
        "    assistant_dict = dict(response[\"choices\"][0][\"message\"])\n",
        "    messages.append(assistant_dict)\n",
        "    print(\"Assistant: \", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\")"
      ],
      "metadata": {
        "id": "HhjJSRBXBvI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919d5175-b2b0-43d9-8605-2527a8976746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User:  Explain what pi is.\n",
            "Assistant:  Pi, denoted by the Greek letter π, \n",
            "\n",
            "User:  Summarize this in two bullet points.\n",
            "Assistant:  - Pi (π) is a mathematical constant that \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3:Going Beyond Text Completions"
      ],
      "metadata": {
        "id": "4qXkjfsa4TZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text moderation"
      ],
      "metadata": {
        "id": "fIZbEM86QCZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Moderation endpoint\n",
        "response = openai.Moderation.create(\n",
        "    model=\"text-moderation-latest\",\n",
        "    input=\"My favorite book is How to Kill a Mockingbird.\"\n",
        "    )\n",
        "\n",
        "# Print the category scores\n",
        "print(response[\"results\"][0][\"category_scores\"])"
      ],
      "metadata": {
        "id": "WuLAYr_L8F7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech-to-Text Transcription with Whisper"
      ],
      "metadata": {
        "id": "RIiJnfnpQE4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's Whisper model has speech-to-text capabilities that can be used to create audio transcripts or translate audio from one language into an English transcript. The model supports many of the most common audio file formats, but does place a limit on the size of the audio file. Whisper has potential applications in automating business meeting transcripts and in accessibility features like caption generation. In this video, we'll discuss speech-to-text transcription."
      ],
      "metadata": {
        "id": "JyD2kmlrTxRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a podcast transcript"
      ],
      "metadata": {
        "id": "7Qd_Pd1PmEgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the openai-audio.mp3 file\n",
        "audio_file = open(\"audio-logan-advocate-openai.mp3\", \"rb\")\n",
        "\n",
        "# Create a transcript from the audio file\n",
        "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "# Extract and print the transcript text\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "NPWOWHIjQDUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794ad6db-ad56-4898-8c76-14422f798668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there, Logan, thank you for joining us on the show today. Thanks for having me. I'm super excited about this. Brilliant. We're going to dive right in, and I think ChatGPT is maybe the most famous AI product that you have at OpenAI, but I'd just like to get an overview of what all the other AIs that are available are. So I think two and a half years ago, OpenAI released the API that we still have available today, which is essentially our giving people access to these models. And for a lot of people, giving people access to the model that powers ChatGPT, which is our consumer-facing first-party application, which essentially just, in very simple terms, puts a nice UI on top of what was already available through our API for the last two and a half years. So it's sort of democratizing the access to this technology through our API. And if you want to just play around with it as an end user, we have ChatGPT available to the world as well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transcribing a non-English language"
      ],
      "metadata": {
        "id": "lypRnQFWmQCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.m4a file\n",
        "audio_file= open(\"audio-portuguese.m4a\", \"rb\")\n",
        "\n",
        "# Create a transcript from the audio file\n",
        "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB1xi1cEmQLl",
        "outputId": "39b28d77-d2b9-4dfa-fc48-5bc89bfa45ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá, o meu nome é Eduardo, sou CTO no Datacamp. Espero que esteja a gostar deste curso que o James e eu criamos para você. Esta API permite enviar um áudio e trazer para inglês. O áudio original está em português.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech Translation with Whisper"
      ],
      "metadata": {
        "id": "M9TpJOs8WBXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Whisper model not only has the ability to transcribe audio into the language it's in, but also translate and transcribe audio in one go. This is currently limited to an English transcript, so we can translate and transcribe German into English, but not German into French. Like with its transcription functionality, Whisper can translate audio from most common audio file types up to a particular size limit.\n",
        "\n",
        "The performance of Whisper can vary wildly depending on audio quality, the language the audio is recorded in, and the model's knowledge of the subject matter. Before creating a full-fledged application on this model, we'll need to test that the model's performance is sufficiently good for the particular use case."
      ],
      "metadata": {
        "id": "BoZyVLy1WXrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating Portuguese"
      ],
      "metadata": {
        "id": "FxSDpZF8h7OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.m4a file\n",
        "audio_file = open(\"audio-portuguese.m4a\", \"rb\")\n",
        "\n",
        "# Create a translation from the audio file\n",
        "response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
        "\n",
        "# Extract and print the translated text\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "FrzSbtNOZv57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a8cc7-6d01-4a1a-bcd5-612a0fddda89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Eduardo, I am a CTO at Datacamp. I hope you are enjoying this course that James and I have created for you. This API allows you to send an audio and bring it to English. The original audio is in Portuguese.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating with prompts"
      ],
      "metadata": {
        "id": "zrU-NyfjiFY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.wav file\n",
        "audio_file = open(\"mandarin-full.wav\", \"rb\")\n",
        "\n",
        "# Write an appropriate prompt to help the model\n",
        "prompt = \"The audio relates to a recent World Bank report\"\n",
        "\n",
        "# Create a translation from the audio file\n",
        "response = openai.Audio.translate(\"whisper-1\", audio_file, prompt=prompt)\n",
        "\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbcQN35_iG65",
        "outputId": "01e950c7-dc19-4ced-b2a1-eeb933877516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The World Bank said in its latest economic outlook report that the global economy is in a dangerous state. As interest rates rise, consumer spending and corporate investment will slow down, economic activities will be impacted, and the vulnerability of low-income countries will be exposed. Global economic growth will be significantly slowed down, and the stability of the financial system will be threatened.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Models"
      ],
      "metadata": {
        "id": "ushybA9tZwXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaining is when models are combined by feeding the output from one model directly into another model as an input. We can chain multiple calls to the same model together or use different models."
      ],
      "metadata": {
        "id": "lSjFDdRcZzOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying audio language"
      ],
      "metadata": {
        "id": "uYIEP1vyibUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.wav file\n",
        "audio_file = open(\"arne-german-automotive-forecast.wav\", \"rb\")\n",
        "\n",
        "# Create a transcription request using audio_file\n",
        "audio_response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "transcript=audio_response[\"text\"]\n",
        "prompt= \"Discover the language used in \"+ transcript\n",
        "\n",
        "# Create a request to the API to identify the language spoken\n",
        "chat_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\":prompt}\n",
        "    ]\n",
        ")\n",
        "print(chat_response[\"choices\"][0][\"message\"]['content'])"
      ],
      "metadata": {
        "id": "m4EJCzdAQD_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3650d1f5-cb39-4897-ad30-dd3ccdae1382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language used in the given text is German.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating meeting summaries"
      ],
      "metadata": {
        "id": "Hv0T0jSKidNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the datacamp-q2-roadmap.mp3 file\n",
        "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
        "\n",
        "# Create a transcription request using audio_file\n",
        "audio_response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "transcript=audio_response[\"text\"]\n",
        "prompt=\"summarize the following transcript into concise bullet points: \" + transcript\n",
        "\n",
        "# Create a request to the API to summarize the transcript into bullet points\n",
        "chat_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "print(chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfvigJUXic1o",
        "outputId": "f05405ef-e0a1-4b1f-dec0-14f144062f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Technical courses offered: OpenAI API courses and Python course\n",
            "- OpenAI API courses focus on programming with GPT and Whisper, including tasks like transcribing meeting notes using Python code\n",
            "- Understanding Artificial Intelligence course provides a broad background on AI beyond just new models\n",
            "- Artificial Intelligence Ethics course highlights the importance of doing AI correctly to avoid harm to the business, organization, and customers\n",
            "- Data literacy courses are also available, with a special emphasis on forming analytical questions to bridge the communication gap between technical and non-technical individuals\n",
            "- Communication is highlighted as a key aspect for better data science\n",
            "- The \"forming analytical questions\" course is recommended for both technical and non-technical individuals to improve communication in data science\n"
          ]
        }
      ]
    }
  ]
}