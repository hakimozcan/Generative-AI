{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "R1fYqsDy_OjI",
        "QpzbGDul_SVo"
      ],
      "authorship_tag": "ABX9TyMN5yprbuQ8C6H2SzGO8LVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hakimozcan/Generative-AI/blob/main/working_with_the_openai_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "R1fYqsDy_OjI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZQZg2WBbpjeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f6ab90-3ca5-48a0-8f35-85c08d548738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI Python API library\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "QpzbGDul_SVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OpenAI Python API library\n",
        "import openai"
      ],
      "metadata": {
        "id": "rt7JZNPJqC7a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Introduction to the OpenAI API\n",
        "\n"
      ],
      "metadata": {
        "id": "WolVslbI_Zh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OpenAI API provides a platform to access and utilize advanced artificial intelligence models developed by OpenAI, including the widely-known ChatGPT. It serves as a tool to integrate AI functionalities into various applications, without requiring in-depth knowledge of AI or machine learning. The API acts as a bridge between the user's requests and the AI models, allowing for customization and application in a range of real-world tasks using Python programming. This makes it a valuable resource for software and data profesionals looking to incorporate AI features into their products and services."
      ],
      "metadata": {
        "id": "10vWjvBg-EK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API request"
      ],
      "metadata": {
        "id": "3BjgYNsr-nz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making requests to the OpenAI API involves understanding and using multiple API endpoints. Authentication is required for accessing these endpoints through a unique API key. Using the OpenAI API may incur costs, depending on the model and the size of data processed. Thus, it's important to refer to API documentation for detailed instructions on endpoint usage and authentication setup. To make a request, one can use OpenAI's Python library. This involves setting up an API client in Python, authenticating with the API key, and then creating and sending a request to a specific endpoint, such as the completions endpoint for text generation."
      ],
      "metadata": {
        "id": "zXATFKRIATF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "openai.api_key = \"<OPENAI_TOKEN>\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  # Specify the correct model\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"Who developed ChatGPT?\"\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "aTaB4Arv_aJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3ff386-4e48-4ee4-c377-8fc035d0fef0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-8XWN6bonC8Yp1XAZH3ltIxXJRagGj\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1702999952,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nChatGPT was developed by OpenAI, an artificial intelligence research and deployment\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 6,\n",
            "    \"completion_tokens\": 16,\n",
            "    \"total_tokens\": 22\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the text from the response\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNZjlwx60E1T",
        "outputId": "416deeaf-02c1-4938-fcdb-e738cc21b6b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ChatGPT was developed by OpenAI, an artificial intelligence research and deployment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's API offers a range of models, beyond its well-known GPT series, including text-based ones and the Whisper model for audio transcription and translation. Key API endpoints include:\n",
        "\n",
        "**Completions**: For single-turn tasks, generating logical responses to prompts.\n",
        "\n",
        "**Chat**: Supports multi-turn tasks, useful for conversations, tutoring, and coding.\n",
        "\n",
        "**Moderation**: Checks content against OpenAI's policies, detecting potential violations."
      ],
      "metadata": {
        "id": "AHmBqIiZDaI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: OpenAI's Text and Chat Capabilities"
      ],
      "metadata": {
        "id": "RU_DVK3b_obu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find and replace"
      ],
      "metadata": {
        "id": "-IuT7efSA5aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
        "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "# Extract and print the response text\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RFUlU0R_os1",
        "outputId": "807baf49-24ab-425e-8d09-041da4274a22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "A plane is a vehicle that is typically powered by jet engines or propellers. It has wings, and is designed to carry passengers and/or cargo through the air. Planes have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as long-distance travel, shipping, and military operations. Planes are often associated with adventure, exploration, and globalization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text summarization"
      ],
      "metadata": {
        "id": "DshpXe-JBoik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
        "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=400,\n",
        "  temperature=0.5\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "F8VBnS4E_ovc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0c18c0-216c-43fc-a30e-2b35fc4b724c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "- Investment involves committing money to an enterprise in order to generate income or profit.\n",
            "- Careful analysis, risk assessment, and diversification are important factors in making successful investments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content generation"
      ],
      "metadata": {
        "id": "nxbkiUf8F_Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a catchy slogan for a new fast-food Chinese restaurant\"\n",
        "\n",
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt,\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "ktEww1kkF_NY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4b293d-138e-425d-b404-7147d373e104"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Indulge in the irresistible flavors of China at lightning speed!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying text sentiment"
      ],
      "metadata": {
        "id": "6-SxVSZaJz4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"\"\"classify the sentiment of the following statements as either negative, positive, or neutral:\n",
        "Unbelievably good!\n",
        "Shoes fell apart on the second use.\n",
        "The shoes look nice, but they aren't very comfortable.\n",
        "Can't wait to show them off!\n",
        "\"\"\",\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "P-wndhdaF_Px",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab0ea20-89f4-4e47-9b43-da10ec52b1b4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive\n",
            "Negative\n",
            "Neutral\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorizing"
      ],
      "metadata": {
        "id": "SptlDUSCKDLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Completion endpoint\n",
        "response = openai.Completion.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"Categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, and LVMH\",\n",
        "  max_tokens=100,\n",
        "  temperature=0.5\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "-kJj6mYqF_SH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b75608-1ff3-41bc-b66c-a61915306d59"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Technology: Apple, Microsoft, Alphabet, Amazon, NVIDIA, Tesla\n",
            "2. Energy: Saudi Aramco\n",
            "3. Conglomerate: Berkshire Hathaway\n",
            "4. Social Media: Meta\n",
            "5. Luxury Goods: LVMH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Chat Completion endpoint"
      ],
      "metadata": {
        "id": "w1jSzrj7vg_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the ChatCompletion endpoint\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\",\n",
        "     \"content\": \"You are a helpful data science tutor.\"},\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "# Extract and print the assistant's text response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1QLfu3R2vhKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a782328-5699-428f-ad34-782ac2d61765"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8XWN9VhJ2oq48AyhKgy4IvV6qkn0I\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1702999955,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"A for loop and a while loop are two different types of loops used in programming, but they serve similar purposes, which is to repeat a block of code until a certain condition is met. The main difference between a for loop and a while loop lies in their syntax and how they control the iteration.\\n\\nA for loop is generally used when you know the number of iterations in advance. It takes an initial value, a condition to check for at each iteration, and an update statement to modify the value for the next iteration. The syntax of a for loop is typically as follows:\\n\\n```\\nfor initialization; condition; update {\\n    // code block to be executed\\n}\\n```\\n\\nHere, the initialization statement sets the starting value, the condition is checked before each iteration, and the update statement modifies the value for the next iteration. For example, you can use a for loop to iterate over elements in a list or to perform a specific task a certain number of times.\\n\\nOn the other hand, a while loop is used when you don't know the exact number of iterations in advance, and the loop continues until a certain condition becomes false. The syntax for a while loop is:\\n\\n```\\ninitialization;\\nwhile (condition) {\\n    // code block to be executed\\n    update;\\n}\\n```\\n\\nHere, you set an initial value before entering the loop, and the loop continues as long as the condition remains true. Inside the loop, you perform the necessary operations, and at the end, you update the value to eventually terminate the loop when the condition becomes false. While loops are often used when the number of iterations depends on some changing condition or user input.\\n\\nIn summary, while a for loop is suitable for situations where you know the number of iterations in advance, a while loop is useful when the exact number of iterations is uncertain and depends on a particular condition.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 32,\n",
            "    \"completion_tokens\": 373,\n",
            "    \"total_tokens\": 405\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code explanation"
      ],
      "metadata": {
        "id": "3ao3zcQa303S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
        "import numpy as np\n",
        "\n",
        "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
        "heights = heights_dict.values()\n",
        "print(np.mean(heights))\n",
        "\"\"\"\n",
        "\n",
        "# Create a request to the ChatCompletion endpoint\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": instruction}],\n",
        "  max_tokens=100\n",
        ")\n",
        "\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJYhO2-h32F6",
        "outputId": "ff8c68ef-ba49-4aff-9659-d83cf3e6b65b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code calculates the mean of the values in the \"heights_dict\" dictionary using the numpy library.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-turn chat completions with GPT"
      ],
      "metadata": {
        "id": "ICD6byvx29EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Messages are sent to the Chat Completions endpoint as a list of dictionaries, where each dictionary provides content to a specific role from either system, user, or assistant. For single turn tasks, no content is sent to the assistant role - the model relies only on its existing knowledge, the behaviors sent to the system role, and the instruction from the user."
      ],
      "metadata": {
        "id": "zSbPjDiy3CTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "   model=\"gpt-3.5-turbo\",\n",
        "   # Add a user and assistant message for in-context learning\n",
        "   messages=[\n",
        "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the min() function does.\"},\n",
        "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
        "   ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "JeRLOIeR2-Qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67abc55e-c81b-4e34-c3cd-4e2ac0e720cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type() function returns the type of an object. It can be used to determine or verify the data type of a variable or expression in Python. For example, if you pass an integer to the type() function, it will return <class 'int'>, indicating that the object is an integer. Similarly, if you pass a string, it will return <class 'str'>, for a list it will return <class 'list'>, and so on. This can be particularly useful when you need to perform type-checking or debugging in your code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-context learning"
      ],
      "metadata": {
        "id": "1Pvx1mnZ4F9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "   model=\"gpt-3.5-turbo\",\n",
        "   # Add a user and assistant message for in-context learning\n",
        "   messages=[\n",
        "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the min() function does.\"},\n",
        "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
        "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
        "   ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XF-ioRr4GFT",
        "outputId": "191f2a8e-57b7-4a4a-b2f4-b5829ed56b02"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type() function returns the type of an object. It can be used to find out the type of any value or variable in Python, such as integers, floats, strings, lists, tuples, dictionaries, functions, and more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an AI chatbot"
      ],
      "metadata": {
        "id": "IpEeTbROBzEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
        "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
        "\n",
        "for q in user_msgs:\n",
        "    print(\"User: \", q)\n",
        "\n",
        "    # Create a dictionary for the user message from q and append to messages\n",
        "    user_dict = {\"role\": \"user\", \"content\": q}\n",
        "    messages.append(user_dict)\n",
        "\n",
        "    # Create the API request\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=10\n",
        "    )\n",
        "\n",
        "    # Convert the assistant's message to a dict and append to messages\n",
        "    assistant_dict = dict(response[\"choices\"][0][\"message\"])\n",
        "    messages.append(assistant_dict)\n",
        "    print(\"Assistant: \", response[\"choices\"][0][\"message\"][\"content\"], \"\\n\")"
      ],
      "metadata": {
        "id": "HhjJSRBXBvI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9fbddc-b2cc-4dbd-f49f-b868c07d493e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User:  Explain what pi is.\n",
            "Assistant:  Pi, denoted by the Greek letter π, \n",
            "\n",
            "User:  Summarize this in two bullet points.\n",
            "Assistant:  - Pi, denoted by the Greek letter π \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3:Going Beyond Text Completions"
      ],
      "metadata": {
        "id": "4qXkjfsa4TZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text moderation"
      ],
      "metadata": {
        "id": "fIZbEM86QCZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a request to the Moderation endpoint\n",
        "response = openai.Moderation.create(\n",
        "    model=\"text-moderation-latest\",\n",
        "    input=\"My favorite book is How to Kill a Mockingbird.\"\n",
        "    )\n",
        "\n",
        "# Print the category scores\n",
        "print(response[\"results\"][0][\"category_scores\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuLAYr_L8F7g",
        "outputId": "5315699b-55da-40aa-8b3b-ba82074f7076"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"sexual\": 9.011665724756313e-07,\n",
            "  \"hate\": 5.238259745965479e-07,\n",
            "  \"harassment\": 3.4255714126629755e-05,\n",
            "  \"self-harm\": 5.782478496030308e-09,\n",
            "  \"sexual/minors\": 5.687450155278384e-08,\n",
            "  \"hate/threatening\": 2.622775596705651e-08,\n",
            "  \"violence/graphic\": 8.806916866888059e-07,\n",
            "  \"self-harm/intent\": 9.663713163021725e-10,\n",
            "  \"self-harm/instructions\": 1.604589724979455e-11,\n",
            "  \"harassment/threatening\": 3.3559299481566995e-06,\n",
            "  \"violence\": 0.0500854030251503\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech-to-Text Transcription with Whisper"
      ],
      "metadata": {
        "id": "RIiJnfnpQE4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's Whisper model has speech-to-text capabilities that can be used to create audio transcripts or translate audio from one language into an English transcript. The model supports many of the most common audio file formats, but does place a limit on the size of the audio file. Whisper has potential applications in automating business meeting transcripts and in accessibility features like caption generation. In this video, we'll discuss speech-to-text transcription."
      ],
      "metadata": {
        "id": "JyD2kmlrTxRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a podcast transcript"
      ],
      "metadata": {
        "id": "7Qd_Pd1PmEgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the openai-audio.mp3 file\n",
        "audio_file = open(\"audio-logan-advocate-openai.mp3\", \"rb\")\n",
        "\n",
        "# Create a transcript from the audio file\n",
        "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "# Extract and print the transcript text\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "NPWOWHIjQDUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3d75a9-2aca-4ea6-a059-196a949167a9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there, Logan, thank you for joining us on the show today. Thanks for having me. I'm super excited about this. Brilliant. We're going to dive right in, and I think ChatGPT is maybe the most famous AI product that you have at OpenAI, but I'd just like to get an overview of what all the other AIs that are available are. So I think two and a half years ago, OpenAI released the API that we still have available today, which is essentially our giving people access to these models. And for a lot of people, giving people access to the model that powers ChatGPT, which is our consumer-facing first-party application, which essentially just, in very simple terms, puts a nice UI on top of what was already available through our API for the last two and a half years. So it's sort of democratizing the access to this technology through our API. And if you want to just play around with it as an end user, we have ChatGPT available to the world as well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transcribing a non-English language"
      ],
      "metadata": {
        "id": "lypRnQFWmQCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.m4a file\n",
        "audio_file= open(\"audio-portuguese.m4a\", \"rb\")\n",
        "\n",
        "# Create a transcript from the audio file\n",
        "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB1xi1cEmQLl",
        "outputId": "7d2eccc9-a56f-46f5-8c17-b5e042f50643"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá, o meu nome é Eduardo, sou CTO no Datacamp. Espero que esteja a gostar deste curso que o James e eu criamos para você. Esta API permite enviar um áudio e trazer para inglês. O áudio original está em português.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech Translation with Whisper"
      ],
      "metadata": {
        "id": "M9TpJOs8WBXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Whisper model not only has the ability to transcribe audio into the language it's in, but also translate and transcribe audio in one go. This is currently limited to an English transcript, so we can translate and transcribe German into English, but not German into French. Like with its transcription functionality, Whisper can translate audio from most common audio file types up to a particular size limit.\n",
        "\n",
        "The performance of Whisper can vary wildly depending on audio quality, the language the audio is recorded in, and the model's knowledge of the subject matter. Before creating a full-fledged application on this model, we'll need to test that the model's performance is sufficiently good for the particular use case."
      ],
      "metadata": {
        "id": "BoZyVLy1WXrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating Portuguese"
      ],
      "metadata": {
        "id": "FxSDpZF8h7OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.m4a file\n",
        "audio_file = open(\"audio-portuguese.m4a\", \"rb\")\n",
        "\n",
        "# Create a translation from the audio file\n",
        "response = openai.Audio.translate(\"whisper-1\", audio_file)\n",
        "\n",
        "# Extract and print the translated text\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "FrzSbtNOZv57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469c5c9e-2228-4533-fbf2-d94be29fca93"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Eduardo, I am a CTO at Datacamp. I hope you are enjoying this course that James and I have created for you. This API allows you to send an audio and bring it to English. The original audio is in Portuguese.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating with prompts"
      ],
      "metadata": {
        "id": "zrU-NyfjiFY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.wav file\n",
        "audio_file = open(\"mandarin-full.wav\", \"rb\")\n",
        "\n",
        "# Write an appropriate prompt to help the model\n",
        "prompt = \"The audio relates to a recent World Bank report\"\n",
        "\n",
        "# Create a translation from the audio file\n",
        "response = openai.Audio.translate(\"whisper-1\", audio_file, prompt=prompt)\n",
        "\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbcQN35_iG65",
        "outputId": "b6991744-1296-4d4c-b6e0-ccefeea84a05"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The World Bank said in its latest economic outlook report that the global economy is in a dangerous state. As interest rates rise, consumer spending and corporate investment will slow down, economic activities will be impacted, and the vulnerability of low-income countries will be exposed. Global economic growth will be significantly slowed down, and the stability of the financial system will be threatened.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Models"
      ],
      "metadata": {
        "id": "ushybA9tZwXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaining is when models are combined by feeding the output from one model directly into another model as an input. We can chain multiple calls to the same model together or use different models."
      ],
      "metadata": {
        "id": "lSjFDdRcZzOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying audio language"
      ],
      "metadata": {
        "id": "uYIEP1vyibUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the audio.wav file\n",
        "audio_file = open(\"arne-german-automotive-forecast.wav\", \"rb\")\n",
        "\n",
        "# Create a transcription request using audio_file\n",
        "audio_response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "transcript=audio_response[\"text\"]\n",
        "prompt= \"Discover the language used in \"+ transcript\n",
        "\n",
        "# Create a request to the API to identify the language spoken\n",
        "chat_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\":prompt}\n",
        "    ]\n",
        ")\n",
        "print(chat_response[\"choices\"][0][\"message\"]['content'])"
      ],
      "metadata": {
        "id": "m4EJCzdAQD_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd69720-1589-43c0-8d84-89de430bd01b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language used in the given text is German.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating meeting summaries"
      ],
      "metadata": {
        "id": "Hv0T0jSKidNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the datacamp-q2-roadmap.mp3 file\n",
        "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
        "\n",
        "# Create a transcription request using audio_file\n",
        "audio_response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "transcript=audio_response[\"text\"]\n",
        "prompt=\"summarize the following transcript into concise bullet points: \" + transcript\n",
        "\n",
        "# Create a request to the API to summarize the transcript into bullet points\n",
        "chat_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "print(chat_response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfvigJUXic1o",
        "outputId": "c3acce76-2a09-4950-d867-b8b5f5c39a63"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- OpenAI API courses and Python course focus on programming with GPT and Whisper models\n",
            "- Understanding Artificial Intelligence provides a broad background on the subject\n",
            "- Artificial Intelligence Ethics course highlights the importance of ethical AI practices to avoid harm to businesses, organizations, and customers\n",
            "- Data Literacy courses help bridge the communication gap between technical and non-technical individuals\n",
            "- \"Forming Analytical Questions\" course teaches how to ask effective questions and improve communication in data science\n",
            "- Communication is crucial in data science and highly emphasized in the courses offered by the speaker\n",
            "- Data Literacy course mentioned is already live and a link is provided in the chat.\n"
          ]
        }
      ]
    }
  ]
}
